<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="description" content="None" />
      <link rel="shortcut icon" href="img/favicon.ico" />
    <title>Pix2Pix - Image to Image translation</title>
    <link rel="stylesheet" href="css/theme.css" />
    <link rel="stylesheet" href="css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="assets/_mkdocstrings.css" rel="stylesheet" />
        <link href="css/custom.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Home";
        var mkdocs_page_input_path = "index.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="." class="icon icon-home"> Pix2Pix - Image to Image translation
        </a>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href=".">Home</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#features">Features</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#installation">Installation</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#install-dependencies">Install Dependencies</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#usage">Usage</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#training">Training</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#testing">Testing</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#cli-options">CLI Options</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#training-and-generating-images">Training and Generating Images</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#training-the-model">Training the Model</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#testing-the-model">Testing the Model</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#contributing">Contributing</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#license">License</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#acknowledgments">Acknowledgments</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#contact">Contact</a>
    </li>
    </ul>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="dataloader/">DataLoader</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="encoder/">Encoder</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="decoder/">Decoder</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="generator/">Generator</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="discriminator/">Discriminator</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="trainer/">Trainer</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="test/">Test</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="cli/">CLI</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href=".">Pix2Pix - Image to Image translation</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">Home</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="pix2pix-image-translation">Pix2Pix Image Translation</h1>
<h2 id="overview">Overview</h2>
<p>Pix2Pix is a machine learning project focused on translating images from one domain to another using Conditional Generative Adversarial Networks (cGANs). This tool is designed to work with a wide range of datasets, including custom datasets, for various image translation tasks such as transforming sketch images into photo-realistic images, or black and white images into color.</p>
<h2 id="features">Features</h2>
<ul>
<li>Built with PyTorch, leveraging the power of deep learning for image translation.</li>
<li>Easy-to-use scripts for training and generating synthetic images.</li>
<li>Command Line Interface (CLI) for straightforward interaction.</li>
<li>Supports custom data loaders for diverse datasets.</li>
<li>Adjustable training parameters for model fine-tuning.</li>
</ul>
<h2 id="installation">Installation</h2>
<p>Clone the repository to your local machine:</p>
<pre><code>git clone https://github.com/atikul-islam-sajib/pix2pix.git
cd pix2pix
</code></pre>
<h3 id="install-dependencies">Install Dependencies</h3>
<pre><code>pip install -r requirements.txt
</code></pre>
<h2 id="usage">Usage</h2>
<p>The project supports both training and testing modes. Below are example commands and their explanations.</p>
<h3 id="training">Training</h3>
<p>To start training the Pix2Pix model:</p>
<pre><code class="language-bash">python cli.py --train --dataset path/to/your/dataset.zip --epochs 20 --lr 0.0002 --beta1 0.5 --lambda_value 100 --device cuda --display True
</code></pre>
<h3 id="testing">Testing</h3>
<p>To test the Pix2Pix model:</p>
<pre><code class="language-bash">python cli.py --test --samples 20 --device cuda
</code></pre>
<h3 id="cli-options">CLI Options</h3>
<table>
<thead>
<tr>
<th>Argument</th>
<th>Description</th>
<th>Type</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--dataset</code></td>
<td>Path to the dataset zip file.</td>
<td><code>str</code></td>
<td>None</td>
</tr>
<tr>
<td><code>--epochs</code></td>
<td>Number of epochs for training.</td>
<td><code>int</code></td>
<td>200</td>
</tr>
<tr>
<td><code>--lr</code></td>
<td>Learning rate for the optimizer.</td>
<td><code>float</code></td>
<td>0.0002</td>
</tr>
<tr>
<td><code>--beta1</code></td>
<td>Beta1 hyperparameter for the Adam optimizer.</td>
<td><code>float</code></td>
<td>0.5</td>
</tr>
<tr>
<td><code>--lambda_value</code></td>
<td>Lambda weight for L1 loss.</td>
<td><code>float</code></td>
<td>100</td>
</tr>
<tr>
<td><code>--device</code></td>
<td>Device to run the model ('cuda', 'cpu', 'mps').</td>
<td><code>str</code></td>
<td>'cuda'</td>
</tr>
<tr>
<td><code>--samples</code></td>
<td>Number of samples to generate for testing.</td>
<td><code>int</code></td>
<td>20</td>
</tr>
<tr>
<td><code>--train</code></td>
<td>Flag to initiate the training process.</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td><code>--test</code></td>
<td>Flag to initiate the testing process.</td>
<td>-</td>
<td>-</td>
</tr>
</tbody>
</table>
<h2 id="training-and-generating-images">Training and Generating Images</h2>
<h3 id="training-the-model">Training the Model</h3>
<p>Train your model on any device by adapting the <code>--device</code> option accordingly:</p>
<table>
<thead>
<tr>
<th>Device</th>
<th>Command</th>
</tr>
</thead>
<tbody>
<tr>
<td>CUDA</td>
<td><code>python cli.py --train --dataset path/to/your/dataset.zip --epochs 20 --lr 0.0002 --beta1 0.5 --lambda_value 100 --device cuda --display True</code></td>
</tr>
<tr>
<td>CPU</td>
<td><code>python cli.py --train --dataset path/to/your/dataset.zip --epochs 20 --lr 0.0002 --beta1 0.5 --lambda_value 100 --device cpu --display True</code></td>
</tr>
<tr>
<td>MPS</td>
<td><code>python cli.py --train --dataset path/to/your/dataset.zip --epochs 20 --lr 0.0002 --beta1 0.5 --lambda_value 100 --device mps --display True</code></td>
</tr>
</tbody>
</table>
<h3 id="testing-the-model">Testing the Model</h3>
<p>Generate images with your trained model:</p>
<table>
<thead>
<tr>
<th>Device</th>
<th>Command</th>
</tr>
</thead>
<tbody>
<tr>
<td>CUDA</td>
<td><code>python test.py --test --model_path path/to/model.pth --samples 20 --device cuda</code></td>
</tr>
<tr>
<td>CPU</td>
<td><code>python test.py --test --model_path path/to/model.pth --samples 20 --device cpu</code></td>
</tr>
<tr>
<td>MPS</td>
<td><code>python test.py --test --model_path path/to/model.pth --samples 20 --device mps</code></td>
</tr>
</tbody>
</table>
<h2 id="contributing">Contributing</h2>
<p>Your contributions are welcome! Please follow the standard fork-pull request workflow to submit your improvements or bug fixes.</p>
<h2 id="license">License</h2>
<p>This project is licensed under the MIT License - see the <a href="./LICENSE">LICENSE</a> file for details.</p>
<h2 id="acknowledgments">Acknowledgments</h2>
<p>Thank you to all the contributors of the Pix2Pix project. Special thanks to the authors of the original Pix2Pix paper for their groundbreaking work in image-to-image translation.</p>
<h2 id="contact">Contact</h2>
<p>For questions or suggestions, please contact [atikulislamsajib137@gmail.com].</p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="dataloader/" class="btn btn-neutral float-right" title="DataLoader">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
    
      <span><a href="dataloader/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="js/jquery-3.6.0.min.js"></script>
    <script>var base_url = ".";</script>
    <script src="js/theme_extra.js"></script>
    <script src="js/theme.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>

<!--
MkDocs version : 1.5.3
Build Date UTC : 2024-03-14 21:09:17.557111+00:00
-->
